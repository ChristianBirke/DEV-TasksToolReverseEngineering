---
title: "Vectal Reverse‑Engineering Work Breakdown Table (Enhanced)"
date: 2025-06-16
tags: [Vectal, ReverseEngineering, Table, Enhanced]
---

| ID | Description | Notes | Status | AllDetails-longtext |
| --- | --- | --- | --- | --- |
| 1.1 | Key Objectives |  | Not Started | Vectal is an AI-powered productivity application that combines task management with advanced AI agent capabilities. It serves as a "virtual assistant" to help power users organize tasks, generate content, and autonomously work toward their goals. The key objectives reflect the current product focus and guide the development: 1) Streamline Task Management - Unite tasks, notes, and goals in one system enhanced by AI (no need to switch between apps); 2) Autonomous Task Execution - Enable AI agents to work 24/7 on user-defined tasks and goals without constant supervision; 3) Personalized Productivity - Adapt to each user's context and data (e.g. user documents, preferences) for tailored assistance; 4) Seamless UI/UX - Provide a clear, intuitive interface combining a to-do list style organizer with an AI chat assistant, minimizing friction for the user; 5) Trustworthy Performance - Utilize best-in-class AI models for accuracy and large-context understanding, while maintaining data security and user control. |
| 1.1.1 | Streamline Task Management: Unite tasks, notes, and goals in one system enhanced by AI (no need to switch between apps). |  | Not Started | The first key objective is to streamline task management by uniting tasks, notes, and goals in one system enhanced by AI, eliminating the need to switch between multiple apps. This represents Vectal's core value proposition as a unified productivity platform where users can manage all their work in a single interface, with AI assistance integrated throughout the experience rather than as a separate tool. |
| 1.1.2 | Autonomous Task Execution: Enable AI agents to work 24 / 7 on user‑defined tasks and goals without constant supervision. |  | Not Started | The second key objective focuses on autonomous task execution, enabling AI agents to work continuously (24/7) on user-defined tasks and goals without requiring constant supervision. This is realized through Vectal's flagship "Infinite Thinking" feature, where AI agents can persistently work on complex tasks in the background, breaking them down into subtasks and making progress independently while the user focuses on other activities. |
| 1.1.3 | Personalized Productivity: Adapt to each user's context and data (e.g., user documents, preferences) for tailored assistance. |  | Not Started | The third key objective emphasizes personalized productivity by adapting to each user's context and data, including user documents and preferences, to provide tailored assistance. This is implemented through features like Personalized AI Chips that allow users to customize the AI's knowledge base with their specific information, document integration for context-aware assistance, and the AI's ability to remember and utilize information from previous interactions and attached resources. |
| 1.1.4 | Seamless UI / UX: Provide a clear, intuitive interface combining a to‑do list style organizer with an AI chat assistant, minimizing friction for the user. |  | Not Started | The fourth key objective focuses on providing a seamless UI/UX experience with a clear, intuitive interface that combines a to-do list style organizer with an AI chat assistant, designed to minimize friction for the user. The interface blends familiar productivity app layouts with AI-driven enhancements, keeping the user in control while making AI assistance easily accessible through integrated chat panels and contextual interactions. |
| 1.1.5 | Trustworthy Performance: Utilize best‑in‑class AI models for accuracy and large‑context understanding, while maintaining data security and user control. |  | Not Started | The fifth key objective emphasizes trustworthy performance by utilizing best-in-class AI models for accuracy and large-context understanding, while maintaining data security and user control. This is achieved through Vectal's multi-model AI engine that integrates advanced models like GPT-4.5, Claude 3.7 Sonnet, and Claude Opus, combined with robust security measures including user data isolation, encryption, and strict API usage policies that protect user information. |
| 2.1 | Autonomous AI Agent ("Infinite Thinking") |  | Not Started | Vectal's flagship capability is an autonomous AI agent that can continuously work on tasks in the background. In Infinite Thinking mode, the user describes a goal or complex task, and the AI agent (or team of agents) iteratively plans and executes steps to achieve the goal. The agent can break down high-level objectives into sub-tasks, generate outputs (texts, code, etc.), search for information, and adjust its approach based on intermediate results. This background agent runs 24/7 until the task is completed or the user stops it. The Infinite Thinking feature is unique to Vectal and not available in standard AI chatbots. It effectively functions as a virtual project assistant, persistently making progress without needing repeated prompts. The continuous agent uses long-context AI models to maintain awareness of prior steps and the overall objective. The system may utilize a task queue or workflow engine to iterate the agent's "think-act" cycle. |
| 2.1.1 | *Example*: A user can input a goal like **"Launch a product website next week."** The Infinite Thinking agent will brainstorm a checklist (buy domain, design landing page, write content, set up email list, etc.), then start tackling these items autonomously (e.g., drafting copy, researching competitors). The user can monitor progress or refine the goal while the agent constantly thinks and works. |  | Not Started | For example, a user can input a goal like "Launch a product website next week." The Infinite Thinking agent will brainstorm a checklist (buy domain, design landing page, write content, set up email list, etc.), then start tackling these items autonomously (e.g. drafting copy, researching competitors). The user can monitor progress or refine the goal while the agent "constantly thinks & works" on it. This demonstrates the agent's ability to break down complex, high-level goals into actionable subtasks and then autonomously work on those tasks, providing real value by making tangible progress while the user is away from the application. |
| 2.1.2 | *Uniqueness*: The Infinite Thinking feature is unique to Vectal and not available in standard AI chatbots. It effectively functions as a virtual project assistant, persistently making progress without needing repeated prompts. |  | Not Started | The Infinite Thinking feature is unique to Vectal and not available in standard AI chatbots. It effectively functions as a virtual project assistant, persistently making progress without needing repeated prompts. This sets Vectal apart from conventional AI tools that require constant user input and interaction. Instead of being a reactive assistant that only responds to direct queries, Infinite Thinking operates as a proactive agent that can work independently on complex, multi-step projects over extended periods of time. |
| 2.1.3 | *User Controls*: Users activate Infinite Thinking mode by providing a task / goal description. They can pause or stop the agent at any time. The interface shows status updates or subtasks as the agent works (e.g., "Researching domain options…", "Drafting landing‑page content…"). |  | Not Started | Users activate Infinite Thinking mode by providing a task/goal description. They can pause or stop the agent at any time. The interface shows status updates or sub-tasks as the agent works (e.g. "Researching domain options…", "Drafting landing page content…"). The UI likely displays an "Agent Running" indicator and progress log so the user can oversee what the AI is doing in each session. This gives users full control over the autonomous process while providing transparency into the agent's activities and progress. |
| 2.1.4 | *Technical Notes*: The continuous agent uses long‑context AI models to maintain awareness of prior steps and the overall objective. The system employs a task‑queue or workflow engine to iterate the agent's think‑act cycle until the goal is met. |  | Not Started | The continuous agent uses long-context AI models (see AI Models below) to maintain awareness of prior steps and the overall objective. The system may utilize a task queue or workflow engine to iterate the agent's "think-act" cycle. Vectal's backend likely employs an orchestration loop – possibly built with a workflow automation tool – that allows the agent to plan, execute a step (e.g. via an API call or code run), then re-evaluate the next step until the goal is met. This technical architecture enables the persistent, autonomous operation that distinguishes Infinite Thinking from simple chatbot interactions. |
| 2.2 | Intelligent Task Management and Prioritization |  | Not Started | At its core, Vectal is a task management app enhanced by AI. Users can create tasks, projects, or goals in a to-do list format, and the system will automatically organize and enrich these entries. The intelligent task management includes automatic task breakdown when complex tasks are entered, prioritization and scheduling based on context analysis, contextualization using attached notes and resources, goal tracking with progress monitoring, and analytics and insights to identify workflow patterns and bottlenecks. This AI-enhanced approach transforms traditional task management into an intelligent system that actively helps users organize and optimize their work. |
| 2.2.1 | Automatic Task Breakdown: When a complex task is entered, Vectal's AI can suggest breaking it into smaller subtasks (e.g., "Write quarterly report" → "Gather sales data," "Draft introduction," …). |  | Not Started | When a complex task is entered, Vectal's AI can suggest breaking it into smaller subtasks. For example, adding a task "Write quarterly report" may prompt the AI to create sub-tasks like "Gather sales data," "Draft introduction," etc. The user can accept or adjust these suggestions. This automatic breakdown capability helps users tackle complex projects by decomposing them into manageable, actionable steps, reducing the cognitive load of project planning and ensuring nothing important is overlooked. |
| 2.2.2 | Prioritization and Scheduling: Vectal's agent analyzes task context—deadlines, dependencies, user goals—and can prioritize and schedule tasks accordingly, highlighting important items and proposing optimal workflows. |  | Not Started | Vectal's agent analyzes task context (deadlines, dependencies, user's goals) and can prioritize the task list accordingly. Important or time-sensitive tasks are highlighted, and the AI may propose a schedule or reorder tasks to optimize workflow. The UI likely labels tasks as "High Priority", "Upcoming", etc., and might reorder the list automatically or suggest a daily plan to the user. This intelligent prioritization helps users focus on what matters most and maintains an optimal workflow sequence. |
| 2.2.3 | Contextualization: Each task can carry context (notes, links, attached docs) that the AI uses for better assistance. The agent remembers related information from the user's workspace or previous chats. |  | Not Started | Each task can carry context that the AI uses for better assistance. For example, the user can attach notes or resources to a task; the AI will then consider that information when working on the task. Vectal's agent "contextualizes" tasks by remembering related information from the user's workspace or previous chats. This contextual awareness ensures that AI assistance is relevant and informed by all available information, making interactions more meaningful and productive. |
| 2.2.4 | Goal Tracking: Users can designate tasks as long‑term goals or projects; Vectal tracks progress and displays completion status ("You're 70 % done with Project X"). |  | Not Started | Users can designate certain tasks as long-term goals or projects. Vectal provides goal tracking by monitoring progress on the sub-tasks and displaying completion status. Intelligent insights (like "You're 70% done with Project X") and reminders are provided by the AI. This feature helps users maintain visibility on long-term objectives and stay motivated by seeing tangible progress toward their goals. |
| 2.2.5 | Analytics and Insights: Basic workflow analytics identify bottlenecks, track weekly completions, and surface productivity insights to the user. |  | Not Started | The system includes basic workflow analytics – for example, it might track how many tasks are completed weekly, or identify bottlenecks (tasks that remain open for long). These insights are presented to the user to help improve productivity. Analytics likely include simple charts or stats in a dashboard or in a weekly summary message, giving users data-driven insights into their work patterns and productivity trends. |
| 2.3 | Integrated AI Chat Interface |  | Not Started | Vectal offers a built-in chat interface where users converse with the AI agent for on-demand assistance. This is akin to having ChatGPT inside your productivity app. The chat interface provides context-aware brainstorming, multi-turn conversations, command execution capabilities, embedded results display, and chat history preservation. This integration makes AI assistance seamlessly available within the task management context, eliminating the need to switch between separate tools for AI help and task organization. |
| 2.3.1 | Context‑Aware Brainstorming: The chat is aware of the user's current tasks and context, tailoring answers accordingly. |  | Not Started | The chat is aware of the user's current tasks and context. Users can ask open-ended questions or brainstorm ideas, and the AI will tailor responses using the context of their projects. For instance, asking "How should I approach task X?" will yield advice or a step-by-step plan relevant to that task (pulling in any details from the task description or attached notes). This context awareness makes the AI chat significantly more useful than generic chatbots, as it provides advice specifically tailored to the user's current work situation. |
| 2.3.2 | Multi‑Turn Conversations: Natural dialogue lets users refine questions or dive deeper over several turns. |  | Not Started | The chat supports natural multi-turn dialogue. The AI can remember previous messages in the conversation, allowing users to refine questions or dive deeper. This is useful for clarifying requirements or progressively elaborating a piece of work with the AI's help. The conversational nature enables more sophisticated interactions where users can build on previous exchanges to develop ideas and solutions collaboratively with the AI. |
| 2.3.3 | Command Execution: Users can issue commands in chat (e.g., "Mark Task Y done") and the AI updates the workspace. |  | Not Started | Within chat, the user can also issue commands to control tasks. For example, "Mark Task Y as done" or "Show me progress on Project Z." The AI will respond by updating the task status or displaying the requested info. This likely uses natural language understanding to map user requests to app actions, or uses a slash-command system in chat for certain functions. This integration allows users to manage their tasks through natural conversation rather than clicking through UI elements. |
| 2.3.4 | Embedded Results: AI‑generated outputs (emails, code, summaries) appear directly in chat threads for review. |  | Not Started | When the AI agent completes an autonomous sub-task, it can post the result in the chat. For example, if asked to draft an email or code snippet as part of a task, the output will appear in the chat for the user to review. This keeps a record of AI contributions in a conversational format, making it easy for users to track what the AI has produced and iterate on the results if needed. |
| 2.3.5 | Chat Histories: Vectal stores past conversations so users can revisit and continue previous sessions. |  | Not Started | New in recent update: Vectal now saves chat histories so users can revisit past conversations with their AI assistant. Previous interactions (e.g. brainstorming sessions or agent status updates) are stored and viewable, providing continuity. The UI offers a list of past chat sessions (likely indexed by date or by topic/task) that users can click to reopen. This was a highly requested feature, added to improve continuity and allow referencing earlier AI outputs. Users may also have the option to clear or export chat history. |
| 2.4 | Personalized AI Chips (New in v57) |  | Not Started | One of the latest features is Personalized AI Chips, introduced in Vectal v57. AI Chips are a way for users to extend and customize the AI's capabilities or knowledge for their specific needs. An "AI Chip" is a modular piece of knowledge or skill that can be plugged into the Vectal agent. Chips are personalized, meaning each user can create or select chips relevant to their work. This feature gives Vectal a plug-in architecture for customization, allowing the AI to become smarter for each user's domain without requiring users to train models from scratch. |
| 2.4.1 | Concept: An *AI Chip* is a modular piece of knowledge or skill that can be plugged into the agent for domain‑specific personalization. |  | Not Started | An "AI Chip" is a modular piece of knowledge or skill that can be plugged into the Vectal agent. Chips are personalized, meaning each user can create or select chips relevant to their work. For example, a user might have an "Email Drafting Chip" that knows their writing style and common contacts, or a "Project Management Chip" specialized in their industry terminology. This modular approach allows users to customize the AI's capabilities for their specific use cases and domains. |
| 2.4.2 | Functionality: Chips may bundle datasets or fine‑tuning instructions so the agent produces more tailored outputs. |  | Not Started | When activated, an AI Chip informs the agent's behavior. Technically, a chip could include a dataset (like past writings, project documents) or a set of instructions/fine-tuning that biases the AI. The agent then uses that to produce more tailored outputs. For instance, with a "Financial Reports Chip," the AI would use company-specific metrics or formatting standards whenever asked to prepare a finance report. Implementation-wise, chips may use internal fine-tuning or vector embeddings of user-provided data. |
| 2.4.3 | UI Integration: Users create and toggle chips in a dedicated settings area; chips appear as small badges that can be enabled for specific tasks or chats. |  | Not Started | Users manage AI Chips in the settings or a dedicated "AI Chips" section. They can add a new chip, perhaps by uploading reference documents or inputting specific parameters (e.g. a description of their role or jargon the AI should learn). Chips might be visualized as small labeled elements (resembling chips or badges) that can be toggled on/off for the AI agent. There is likely an interface to enable certain chips for a given task or chat session (for example, turning on the "Coding Helper Chip" when working on a coding task, etc.). |
| 2.4.4 | Examples: Personal Notes Chip, CRM Chip, Financial Reports Chip, Multilingual Vocabulary Chip. |  | Not Started | Common uses might include a Personal Notes Chip (containing the user's uploaded notes/PDFs for the AI to reference), CRM Chip (integrating customer data for drafting sales emails), or Language Chip (if the user works in multiple languages, a chip could contain domain-specific vocabulary). These examples illustrate how chips can be tailored to different professional contexts and workflows, making the AI more effective for specialized tasks. |
| 2.4.5 | Benefit: Provides a plug‑in architecture for customization without requiring users to train models from scratch. |  | Not Started | Personalized AI Chips give Vectal a plug-in architecture for customization. Instead of a one-size-fits-all model, the AI becomes smarter for each user's domain. This feature helps Vectal stand out by allowing a form of personal fine-tuning without requiring the user to train models from scratch. For instance, an uploaded PDF might be turned into an embedding vector – effectively acting as a knowledge "chip" the AI can draw from when needed. "AI Chips" is a newly launched feature and may still be in beta, with specific UI and technical details continuing to evolve. |
| 2.5 | Document and Knowledge Integration (PDF Support) |  | Not Started | Vectal now supports PDF integration, allowing the AI to ingest and work with user-provided documents. This feature significantly expands the agent's capabilities in research and content generation tasks. Users can upload PDF files and the AI agent will parse the text content so it can be used in tasks and conversations. By integrating Claude 3.7 "Sonnet", which supports very large context windows, Vectal's agent can process lengthy documents without losing track. This capability is useful for researchers, students, or professionals who deal with PDFs and need to quickly extract summaries, specific information, or incorporate document data into other work. |
| 2.5.1 | PDF Upload & Parsing: Users upload PDFs; the agent parses text for use in tasks and chat. |  | Not Started | Users can upload PDF files (or potentially other document formats) into Vectal. The AI agent will parse the text content of these files so it can be used in tasks and conversations. For example, a user can attach a PDF report to a task "Summarize this report," and the AI will read the PDF and produce a summary. This parsing capability transforms static documents into dynamic, queryable knowledge that the AI can work with. |
| 2.5.2 | Referencing Documents in Chat: Users can ask questions about uploaded PDFs ("What are the key findings in Report.pdf?"). |  | Not Started | In the chat interface, users can ask questions about an uploaded PDF (e.g. "What are the key findings in Report.pdf?"). The AI will answer based on the document's content, effectively functioning as a PDF Q&A assistant. This turns document interaction from a static reading exercise into a dynamic conversation where users can quickly extract specific information or explore document contents through natural language queries. |
| 2.5.3 | Large‑Context Handling: Integration of Claude 3.7 "Sonnet" enables processing of lengthy documents in one go. |  | Not Started | By integrating Claude 3.7 "Sonnet", which supports very large context windows, Vectal's agent can process lengthy documents without losing track. This means even PDFs with hundreds of pages can be summarized or analyzed by the AI in one go. In practice, the system might chunk the PDF into sections and use embeddings or the large-context model to handle it efficiently while maintaining coherence across the entire document. |
| 2.5.4 | Use Cases: Summaries, Q&A, extracting data from academic papers, legal contracts, manuals, etc. |  | Not Started | This capability is useful for researchers, students, or professionals who deal with PDFs (academic papers, legal contracts, manuals, etc.). They can quickly get summaries, extract specific information, or let the AI incorporate data from PDFs into other work (for instance, using facts from a PDF in a slide deck the AI is helping draft). The versatility of PDF integration makes it valuable across numerous professional contexts and use cases. |
| 2.5.5 | Technical Architecture: A hybrid of vector‑embedding retrieval and high‑context inference handles very large files efficiently. |  | Not Started | When a PDF is uploaded, the backend either uses an embedding-based retrieval (storing vectors for document paragraphs and retrieving relevant chunks when the AI needs to answer questions) or leverages a high-context model (like Anthropic Claude with ~100k token input) to read the entire document in prompts. Vectal likely uses a hybrid approach – for very large documents, it may do retrieve-and-read (to remain efficient), but for moderately sized documents, the agent can feed them directly into the context of a model like Claude if within limits. Either way, PDF content is processed securely and stored only for the user's use. |
| 2.6 | Web Research Agent ("Ultra Search") |  | Not Started | To complement its productivity features, Vectal includes an AI-powered web research agent known as Ultra Search. This was introduced as a new AI agent that can perform deep web research on behalf of the user. Users can ask Vectal to find information on the web and Ultra Search will autonomously perform search queries, crawl web pages, and compile findings. It goes beyond a normal search by synthesizing information and providing a concise report with relevant details. Ultra Search is powered by external search engines like Perplexity and can be used both directly by users and automatically by the Infinite Thinking agent when external information is needed. |
| 2.6.1 | Deep Research Capability: Users invoke Ultra Search to autonomously query the web and synthesize findings. |  | Not Started | Users can ask Vectal to find information on the web (e.g. "Find the latest trends in remote work adoption"). Ultra Search will autonomously perform search queries, crawl web pages, and compile findings. It goes beyond a normal search by synthesizing information and providing a concise report with relevant details. The agent is described as "taking deep research to the next level" and providing personalized insights you won't find anywhere else. This transforms web research from a manual, time-consuming process into an automated, intelligent synthesis of information. |
| 2.6.2 | Integration with External Search APIs: Powered by engines like Perplexity; crawls pages and compiles concise reports with citations. |  | Not Started | Under the hood, Ultra Search leverages external knowledge sources. It is "powered by Perplexity" and similar advanced search engines. This suggests Vectal's agent uses APIs or techniques from systems like Perplexity.ai (which answer queries with summarized web information and citations). The AI agent can browse web results, read content, and combine information across multiple sources to provide comprehensive research reports with proper attribution. |
| 2.6.3 | User Experience: Triggered via command or dedicated input; results appear in chat with references. |  | Not Started | The user accesses Ultra Search either via a special command or a dedicated input. For example, typing a query in a designated search bar or saying "@search: [topic]" in chat could trigger this mode. The output is presented in the chat as a research summary, often with reference links or source context (similar to how a search engine might provide snippets). This integration makes web research feel natural within the chat interface while providing credible, cited information. |
| 2.6.4 | Continuous Discovery: Infinite Thinking agents can call Ultra Search when external data is needed mid‑workflow. |  | Not Started | Ultra Search might also be employed by the Infinite Thinking agent when needed. If the autonomous agent encounters a question it can't answer internally, it can invoke Ultra Search to retrieve external information. This makes the autonomous workflow more robust, as the AI isn't limited to what the user has given – it can fetch new data from the internet when working on tasks. This integration creates a more capable autonomous system that can handle information gaps dynamically. |
| 2.6.5 | Access and Limits: Free for all users initially, with heavier usage quotas reserved for Pro subscribers. |  | Not Started | Initially, Ultra Search is available to all users for free (as per the launch announcement). However, heavy usage may be limited on the free tier (see Pricing). The agent is designed to handle both general queries and specific ones; users are encouraged to use it for any fact-finding or knowledge gathering tasks. For example, a user planning a report can ask, "Use Ultra Search to gather recent statistics on e-commerce growth." Vectal's agent will search the web, find the stats, and return an organized summary, saving the user from manually googling and sifting through sites. |
| 2.7 | Multi‑Model AI Engine |  | Not Started | To deliver these features, Vectal runs on a sophisticated multi-model AI backend. Rather than relying on a single AI model, it integrates several of the world's smartest models, selecting the best one for each task. Recent updates have expanded the model lineup to include GPT-4.5 for Pro users, Anthropic Claude 3.7 "Sonnet" for reasoning and large-context understanding, Claude "Opus" for extended context handling, and other models including open-source and experimental options. The system automatically chooses the appropriate model based on the operation, and by combining multiple models, Vectal ensures higher accuracy and fewer blind spots across different types of tasks. |
| 2.7.1 | GPT‑4.5 Access: Pro users tap an advanced GPT‑4 variant for high‑accuracy, complex tasks. |  | Not Started | Vectal Pro users have access to what is referred to as GPT 4.5. This appears to be an advanced version of OpenAI's GPT-4 (with improved capabilities or plugins, as of 2025). It offers high reasoning ability and creativity. GPT 4.5 is used for tasks requiring top-tier accuracy, coding, or complex content generation. GPT-4.5 is known to be costly and normally available via limited channels, but Vectal provides it affordably through its subscription, making advanced AI capabilities accessible to more users. |
| 2.7.2 | Anthropic Claude 3.7 "Sonnet": Integrated for long‑context reasoning and reduced censorship. |  | Not Started | This is an AI model from Anthropic that excels at reasoning and large-context understanding. Claude 3.7 (code-named "Sonnet") was integrated into Vectal in early 2025. It's known as one of the best AI models for complex tasks and has a more open-ended, less censored reasoning approach. Vectal uses Claude 3.7 for tasks like Infinite Thinking, where the model's ability to maintain long discussions (or read long documents) is crucial. Free users have access to Claude 3.7 Sonnet in a limited capacity, while Pro users enjoy unlimited access. |
| 2.7.3 | Claude "Opus" (Extended Context): Supports extremely large inputs (≈ 100 k tokens) for deep analysis. |  | Not Started | New in v57, Vectal announced support for "Claude 4 – Opus". This likely refers to an Anthropic model variant with even larger context window or an upgraded version of Claude. Opus is used for handling extremely large inputs (such as very big PDFs or extensive project histories). With Claude Opus, Vectal's agent can autonomously analyze or generate long-form content (e.g., an entire ebook or codebase). "Opus" is Anthropic's high-context model – possibly Claude 100k or a next-gen model beyond Sonnet. This enables the agent to read ~100,000 tokens of text in one go, which is instrumental for deep research and document-heavy tasks. |
| 2.7.4 | Other Models: Ecosystem includes open‑source and experimental models (e.g., DeepSeek R1). |  | Not Started | Vectal's ecosystem is model-agnostic; it integrates any model that provides value for a task. For instance, a model nicknamed "Sonnet" is in use (Anthropic) and the mention of "DeepS R1" suggests an experimental integration of DeepSeek R1, a new model optimized for reasoning (a potential GPT-4 competitor from a research lab). These additions indicate Vectal stays at the cutting edge, incorporating models that might not be widely available elsewhere, giving users access to the latest AI capabilities as they become available. |
| 2.7.5 | Model Selection & Personalization: Backend auto‑routes requests to the optimal model; users needn't choose. |  | Not Started | The system automatically chooses the appropriate model based on the operation. For a short casual query, it might use a faster model (like an improved GPT-3.5 or Claude Instant). For a detailed coding task or analysis, it will invoke GPT-4.5 or Claude Sonnet. Users on Pro plan can effectively leverage "all of the above" without worrying about separate APIs – Vectal abstracts it away. There may be a setting or indicator of which model is used (for transparency), but the selection is largely behind-the-scenes for a seamless experience. |
| 2.7.6 | Performance and Quality: Model mix increases accuracy and reduces hallucinations across domains. |  | Not Started | By combining multiple models, Vectal ensures higher accuracy and fewer blind spots. If one model is weaker on a certain query, another can be used. The AI agents have been observed to produce high-quality outputs across domains (text, code, summaries) and have reduced incidences of hallucination thanks to the model mix. The inclusion of advanced models (GPT-4.5, Claude 3.7) also means the AI can follow complex user instructions more reliably and handle nuanced tasks that simpler models would struggle with. |
| 2.8 | Security and Data Privacy |  | Not Started | Vectal takes data security and privacy seriously, especially given the sensitive nature of personal tasks and documents. The security framework includes user data isolation where all user-provided data is stored separately per user, cloud storage and encryption for data at rest and in transit, careful API usage with third-party AI providers, user controls for data deletion and chat history management, and compliance efforts to adhere to privacy regulations like GDPR. As of 2025, Vectal is a small startup but is actively improving transparency and security features. |
| 2.8.1 | User Data Isolation: Each user's data is siloed; no cross‑account access. |  | Not Started | All user-provided data (tasks, documents, chat history) is stored in a way that is isolated per user. No other user's agent can access your data, and AI chips or document contents are not used to train models in a way that others benefit. This isolation ensures that sensitive personal or business information remains private and cannot be accessed by other users of the platform. |
| 2.8.2 | Cloud Storage & Encryption: Data at rest encrypted in secure cloud storage; transport encrypted via HTTPS. |  | Not Started | Data at rest (e.g. task lists, uploaded PDFs) is stored on secure cloud databases with encryption. In transit, all communications between the front-end app, backend, and AI model providers are encrypted via HTTPS. This provides comprehensive protection for user data both when it's stored and when it's being transmitted between different parts of the system. |
| 2.8.3 | API Usage: Third‑party model providers process data only for fulfilling requests; opt‑out of data retention when possible. |  | Not Started | Vectal relies on third-party AI APIs (OpenAI, Anthropic, etc.) to process content. It employs those under strict terms of service that prohibit those providers from using the data beyond fulfilling the query. Wherever possible, Vectal opts out of data logging by these providers to protect user information. This ensures that user data sent to AI models is processed only for the immediate request and not retained or used for other purposes. |
| 2.8.4 | User Controls: Users can delete data and disable chat history; deletions propagate across storage after a grace period. |  | Not Started | Users can delete tasks or files they have uploaded, and such deletions will remove the data from Vectal's servers after a grace period. Additionally, the new Chat History feature can be disabled if a user prefers not to save conversations. The app might include a "Privacy" settings page where a user can toggle chat history on/off and manage data retention preferences, giving users control over their data storage and privacy settings. |
| 2.8.5 | Compliance: Aims to satisfy GDPR with export / delete requests and transparent data handling. |  | Not Started | As of 2025, Vectal is a small startup, but it aims to adhere to privacy regulations (GDPR, etc.) by allowing data export/deletion on request. The team is actively improving transparency, possibly adding features like chat export (to PDF or text) and detailed logs of AI actions for user review. This commitment to compliance helps build trust with users and ensures the platform can be used in regulated environments. |
| 4.1 | Task Details pane shows editable attributes (due date, priority, tags). |  | Not Started | Clicking on a task opens the Task Detail view, which is typically a pane or modal on the right side of the dashboard. At the top, the task name can be edited and attributes like due date, priority, tags, or assignees (if multi-user in future) are shown. Users can add a longer description or checklist items as sub-tasks. This section functions like a normal project management tool, providing all the metadata and organizational features users expect from task management software. |
| 4.2 | AI Assistant chat is contextual to the task, supporting Q&A and inline agent logs. |  | Not Started | The bottom or side of the Task Detail pane contains a mini-chat interface specifically for this task. It might be labeled "Agent Assistant" or "Chat with AI about this task." Here, the conversation is contextual to the task – the AI automatically knows to focus only on this task's content. The user can ask the AI questions or give instructions related to the task, and the AI's responses appear threaded in this panel. If Infinite Thinking is active on this task, this panel will also display the agent's log with messages like "AI Agent: Broke task into 3 subtasks." or "AI Agent: Completed subtask 1 – see draft document attached." |
| 4.3 | User Interaction Examples include drafting, brainstorming, or summarizing via quick‑action buttons. |  | Not Started | There are likely quick-action buttons in the chat panel for common uses: e.g. a "Summarize Task" button (AI produces a summary of all notes/subtasks), or "Brainstorm" (AI generates ideas or next steps). These shortcuts help non-technical users leverage the AI without typing a prompt every time. The user can interact at any point, confirming or adjusting the agent's work, making the collaboration between human and AI seamless and efficient. |
| 4.4 | Attachments & Documents: Users upload files; AI can analyze and propose next steps. |  | Not Started | In the task detail view, users can attach files (this is where PDF support comes in). An Attach File button lets the user upload a PDF or other documents to the task. Once attached, the AI is immediately aware of it. The UI might show a file icon, and possibly an "Analyze" button next to each attachment. If the user clicks analyze (or asks a question about the file in chat), the AI will read the file and respond. After analysis, the AI might even auto-suggest some task updates. For example, attaching a requirements PDF could make the AI say: "I've read Requirements.pdf. Do you want me to extract key tasks from it?" |
| 4.5 | Subtasks & AI‑generated items appear with distinct icons and can be accepted or edited. |  | Not Started | As the AI breaks down tasks, these subtasks appear in the detail (and possibly main list). They could be marked with a special icon (to denote "suggested by AI"). The user can accept them (adding to their list) or ignore/edit them. Once accepted, the AI can act on them as well. This visual distinction helps users understand which items were created by the AI versus those they created themselves, while maintaining full control over what gets added to their task list. |
| 4.6 | Collaboration: AI adapts to user edits, keeping human + agent in sync. |  | Not Started | If the user makes changes (checks off a subtask, edits a description), the AI is designed to notice and adapt. The chat might produce a confirmation: "Noted that you completed subtask 2. I will focus on the remaining parts." This interactive loop ensures the user and AI stay in sync, creating a collaborative environment where both human and AI contributions are acknowledged and integrated smoothly. |
| 4.7 | Toggle exists to disable AI assistance per task if desired. |  | Not Started | There may be a toggle to turn off AI assistance for a particular task, in case the user wants to handle it manually. In that case, the chat panel can be minimized or disabled for that task. This gives users the flexibility to choose when they want AI assistance and when they prefer to work independently, maintaining user control over their workflow preferences. |
| 5.1 | Global Assistant Chat tackles questions not tied to a specific task. |  | Not Started | Apart from task-specific chats, Vectal likely provides a global AI chat (a general chatbot interface not tied to a single task). This could be accessed via a "Chat" or "Assistant" icon in the app's navigation bar. Here the user can ask anything not necessarily linked to a task, e.g., "Give me productivity tips" or "What's the weather?". It's essentially a general-purpose AI companion that uses the same underlying models but without injecting task context, though it does have access to the user's profile or preferences if relevant. |
| 5.2 | Chat Interface features large text input and scrolling history. |  | Not Started | This chat interface is similar to ChatGPT's: a large text input box and a history of the conversation above it. The user can engage in open Q&A or creative brainstorming here beyond a single task's scope. The interface is designed for extended conversations and supports the full range of AI capabilities that Vectal offers, making it a powerful tool for general assistance and ideation. |
| 5.3 | Chat Histories panel lists prior sessions for continuity. |  | Not Started | The app now provides a way to view past chat sessions. In the UI, this might appear as a sidebar in the global chat area listing recent conversations by date, or a dropdown of past sessions. Each session can be reopened. For example, if a user had a long brainstorming chat last week, they can find it in History and continue the conversation. This feature was added to provide continuity and allow users to reference earlier AI outputs and conversations. |
| 5.4 | Session Naming auto‑labels conversations based on first prompt; users may rename. |  | Not Started | Possibly, Vectal auto-names chat sessions based on the first user query (similar to ChatGPT). E.g., "Brainstorm Marketing Ideas – Jun 10". The user might also rename sessions for clarity. This automatic naming helps users quickly identify and locate specific conversations from their chat history, while still allowing customization for better organization. |
| 5.5 | History Management lets users delete sessions for privacy. |  | Not Started | The History management includes the ability to delete a session or clear all history, addressing privacy needs. Users have full control over their conversation history and can remove any sessions they no longer want stored. This privacy control is important for users who may discuss sensitive topics or simply want to maintain a clean conversation history. |
| 5.6 | UI differentiates AI vs. user messages via avatars and timestamps. |  | Not Started | There might be an indicator or timestamp on each message bubble to differentiate between AI vs user messages, and an avatar (perhaps the Vectal logo or an "AI" icon) to mark AI responses. This visual differentiation helps users quickly scan conversation history and understand the flow of the conversation between themselves and the AI assistant. |
| 5.7 | Ultra Search answers in global chat include inline citations. |  | Not Started | If using Ultra Search in global chat, the AI's answer might include footnotes or inline citations (just as Perplexity does) – possibly formatted as hyperlink references (but given UI limitations, Vectal might present them as part of the answer text). This ensures that web research results are properly attributed and users can verify the sources of information provided by Ultra Search. |
| 6.1 | Account Settings show profile, subscription tier, and model‑provider status. |  | Not Started | The Settings screen allows users to configure their experience and manage account details. Basic profile info, subscription status (Free or Pro), and a connection status for model providers (for transparency it might show e.g. "OpenAI API: Operational") are displayed. If using Google sign-in, account linking info is shown here. This transparency helps users understand their account status and the operational status of the AI services they're using. |
| 6.2 | Plan Upgrade path highlights Pro benefits. |  | Not Started | Free users see an option here to upgrade to Pro, with a summary of Pro benefits (e.g. "Access to GPT-4.5, unlimited Claude usage, 20× more AI runtime, etc."). This upgrade path makes it easy for users to understand the value proposition of the Pro plan and convert when they need additional capabilities or higher usage limits. |
| 6.3 | AI Chips Management lists, creates, or toggles personalized chips. |  | Not Started | A section in settings lists the user's AI Chips (if any). Users can create new chips or modify/delete existing ones. For creation, a form or wizard is provided – for example: Name of chip, Upload supporting files or enter data, Choose chip type. After creation, the chip appears in the list with an enable/disable toggle. This management interface gives users full control over their personalized AI capabilities. |
| 6.4 | Integration Settings placeholder for forthcoming calendar / email hooks. |  | Not Started | Although Vectal currently doesn't have third-party app integrations (like calendars or email) publicly, the settings might include placeholders or forthcoming integration toggles. Possibly coming soon features like "Connect Google Calendar – Coming Soon" if they plan to integrate scheduling, or "Email Integration – Beta". For now, integration is largely with models (handled behind scenes) and login, so this section may be minimal but represents future expansion possibilities. |
| 6.5 | Notifications preferences for task completion and daily summaries. |  | Not Started | Users can set preferences for notifications (e.g. email or push notifications when the AI finishes a long-running task, or daily summaries). This ensures the user is alerted if an autonomous agent completes something important or needs approval to continue. Notification preferences help users stay informed about AI activity without being overwhelmed by constant updates. |
| 6.6 | Data & Privacy controls for export, deletion, and chat‑history toggle. |  | Not Started | As noted, settings will include options related to data (download data, clear chat history, etc.). For example, a "Clear all chat history" button or a "Export my tasks" feature could be present. These privacy controls give users agency over their data and align with compliance requirements and user expectations for data control. |
| 6.7 | Experimental Features let power users test beta models / settings. |  | Not Started | Power users might access experimental toggles (if the team exposes them). For instance, enabling "Beta AI model XYZ" or adjusting the aggressiveness of Infinite Thinking (like how many steps it takes autonomously before checking in). These are speculative, but given the founder's AI enthusiast audience, advanced settings might exist for users who want to experiment with cutting-edge features. |
| 7.1 | Visual Theme: Clean, light UI with brand‑color highlights for AI actions. |  | Not Started | Vectal's design is clean and modern, with a focus on clarity. Likely a light theme with crisp typography (for readability of long AI-generated text). Important elements (like AI suggestions or active tasks) are highlighted with a distinct color (possibly the brand color). Icons are used to denote AI-related actions (e.g. a robot icon for the agent, a search icon for Ultra Search results). The visual design prioritizes readability and clarity, especially important when displaying AI-generated content. |
| 7.2 | Feedback and Status indicators ("AI is thinking…") reassure user of activity. |  | Not Started | The UI provides real-time feedback when AI actions are happening. For example, when the agent is working, a small loading spinner or status line ("AI is thinking…") is shown, so the user knows the system is active and hasn't frozen. When Ultra Search is fetching info, a message like "Searching the web…" might appear. Completed AI actions often come with a checkmark or highlight to draw user attention to new outputs (like "AI completed this subtask"). This feedback system helps users understand when the AI is working and provides confidence that the system is responsive. |
| 7.3 | Mobile Access: Responsive single‑column layout for basic mobile usage; heavy features best on desktop. |  | Not Started | While primarily a web app, Vectal's interface likely has a responsive design for mobile browsers. Users can check tasks and even chat with the AI on the go. The layout might condense to a single-column view on mobile, with a menu to switch between tasks and chat. Some advanced features (like heavy PDF analysis) are best on desktop due to complexity, but basic usage is possible on mobile. Native mobile apps may be planned but as of mid-2025, the focus is on the web platform. |
| 8.1 | Client Application (Frontend) |  | Not Started | The front-end is a web application (likely built with React or a similar modern framework) that handles the UI. It communicates with the backend via secure HTTPS API calls (for sending user inputs, receiving AI responses, fetching task data, etc.). The client manages real-time updates using websockets or long-polling – for example, to stream chat responses from the AI or to update the task list when the AI agent completes a task in the background. The interface is optimized for responsiveness to handle dynamic content like an updating chat log. |
| 8.2 | Application Server (Backend) |  | Not Started | The core of Vectal's backend is an application server that exposes RESTful or GraphQL APIs to the client. This server handles authentication & user management, task & data storage, AI orchestration service, long-running agent controller, file processor, and rate limiting & usage monitoring. The backend serves as the central hub that coordinates all the different components and services that make Vectal's AI-powered productivity features possible. |
| 8.2.1 | Authentication & User Management |  | Not Started | Handles Google OAuth login as well as any direct sign-ups. Maintains user profiles, subscription status (free/pro), and permission checks for features (e.g. limiting free users' heavy usage features). This component ensures secure access to the platform and manages user permissions based on their subscription level and account status. |
| 8.2.2 | Task & Data Storage |  | Not Started | Interfaces with a database to store task lists, project info, notes, and links to user-uploaded files. Likely uses a cloud database (SQL or NoSQL) for structured data (tasks, user profile) and cloud storage (S3 or similar) for files like PDFs. This storage layer maintains all user data in a structured, queryable format while handling file storage efficiently. |
| 8.2.3 | AI Orchestration Service (model routing, prompt construction) |  | Not Started | This is a crucial subsystem that orchestrates calls to various AI models and tools. When the user enters a prompt or a task requires AI processing, this service decides which model or agent to invoke. It handles formatting the prompt with relevant context (e.g., including task details or document text) and sends it to the appropriate AI model API. The orchestration might be implemented with a framework or workflow engine, possibly using a low-code automation tool like n8n to define AI agent workflows, allowing quick updates to agent logic. |
| 8.2.4 | Long‑running Agent Controller (task queue / scheduler) |  | Not Started | For features like Infinite Thinking, a persistent process or scheduler is needed. Vectal likely runs a background worker process (or a set of them) that can maintain an agent's state and loop through the think-act cycle. This could be implemented via a task queue (e.g., Redis/RQ, Celery) where a job represents one iteration of agent reasoning, re-queuing itself until done. The system ensures these background agents do not hog resources – possibly by limiting concurrency or using lower-cost models until needed. |
| 8.2.5 | File Processor (PDF text extraction, vector‑embedding index) |  | Not Started | When PDFs or files are uploaded, a sub-component processes them. This may involve extracting text (using OCR if needed for scanned PDFs, or simply PDF-to-text for digital PDFs). Text is then either indexed into a Vector Database for semantic search or passed directly to a model. If using a vector DB (like Pinecone, Weaviate, etc.), the file's chunks are stored with embeddings so the AI can quickly retrieve relevant parts during a query. This component ensures large files are handled efficiently and that queries only send necessary information to the language model to minimize token usage. |
| 8.2.6 | Rate Limiting & Usage Monitoring |  | Not Started | The server monitors how many requests and how much AI processing each user is doing. Free accounts have caps (e.g. number of tasks automated per day, or tokens used per month). The backend enforces these limits (for example, it might decline an operation or ask the user to upgrade when limits are hit). Pro accounts have higher or no limits, but the system still tracks usage for cost management and may throttle extremely heavy use to maintain performance for all users. |
| 8.3 | AI Models Integration |  | Not Started | Vectal uses external AI model APIs including OpenAI API for GPT-4/4.5 and possibly GPT-3.5 for some tasks, Anthropic API for Claude models (like Claude 3.7 Sonnet, Claude "Opus"), and others like DeepSeek R1 or other models as needed. The architecture might include an AI Model Proxy layer – a unified interface the server code calls, which then routes to the chosen model provider. This abstraction allows adding/removing models without changing the core logic drastically. |
| 8.4 | Front‑end Interaction Example |  | Not Started | When a user types a question in the chat about a PDF: 1) The front-end sends the query to a chat API endpoint with user ID, session ID, and message. 2) The backend receives it, looks up that session's context (sees that an attachment PDF is in context). 3) The AI Orchestration decides to use Claude (due to large context), and fetches the PDF text from the database or vector store. 4) It constructs a prompt with the PDF content or summary + the user's question, and calls Anthropic's Claude API. 5) Claude returns an answer; the backend sends this streaming back to the front-end, and also stores the QA in the chat history DB. 6) The front-end displays the answer to the user in real-time. This all happens within a few seconds for the user. |
| 8.5 | Scalability & Monitoring |  | Not Started | The system is cloud-based and can scale horizontally. The stateless parts (API servers) can multiply behind a load balancer to handle more users. The stateful parts (DB, vector index) are managed as cloud services or on robust instances. Because AI calls are heavy, Vectal likely employs caching for repeated queries and also possibly queues requests at peak times to avoid hitting provider rate limits or incurring extreme costs. Monitoring tools alert the developers if any third-party API is down or if response times spike, so they can switch models or notify users of service degradation. |
| 9.1 | Login Integration via Google OAuth. |  | Not Started | OAuth with Google is supported for quick account creation. This simplifies onboarding and is a secure way to manage identities. No other login methods are mentioned (no Facebook/Apple OAuth yet, though email/password may exist as an alternative). The Google integration makes it easy for users to get started without creating yet another account, reducing friction in the signup process. |
| 9.2 | AI Providers (OpenAI, Anthropic) integrated behind the scenes. |  | Not Started | Vectal integrates with OpenAI, Anthropic, and others as needed (this is an internal integration invisible to the end-user, except for the capabilities it unlocks as described in Multi-Model AI Engine). These integrations provide the core AI capabilities that power all of Vectal's intelligent features, from chat assistance to autonomous task execution. |
| 9.3 | Web Integrations through Ultra Search for real‑time data. |  | Not Started | The Ultra Search feature effectively integrates the app with web search engines and possibly knowledge bases like Wikipedia or specialized APIs (Perplexity). While not a user-configured integration, this means Vectal's agent can tap into the internet's information live. This is important for tasks that need up-to-date data and extends the AI's knowledge beyond its training cutoff. |
| 9.4 | Community & Support via Discord. |  | Not Started | The app provides links to join the Vectal Discord community (accessible via a button in the UI, e.g. at bottom-right or in a Help menu). This isn't an integration in the traditional sense, but it is an ecosystem aspect – users can get support, see daily update notes from the developer, and exchange tips on the Discord server. The rapid iteration (updates "almost every single day" as noted by the team) is communicated here. |
| 9.5 | Future Integrations roadmap: email, calendar, project‑management apps. |  | Not Started | Though not publicly launched as of mid-2025, it's logical that upcoming versions may integrate with email clients (allowing the AI to draft and send emails), calendars (where the agent could schedule meetings or set reminders for tasks), and project management tools (to import/export tasks with Jira, Trello, etc.). These are speculative, but given Vectal's trajectory to be a "super productivity tool", such integrations would add value. They would be approached carefully to maintain user privacy and require user API keys or permissions to connect. |
| 10.1 | Free Tier: Core features with modest AI quotas. |  | Not Started | Anyone can sign up for Vectal and start using it at no cost. The free plan provides the core experience with some limitations: Users can create and manage tasks, use the integrated chat, and even try out the AI agents (Infinite Thinking, Ultra Search, etc.) on a limited basis. Model access: Free users likely get access to standard models and a taste of advanced models but with rate limits. Feature limits: Some advanced features are capped - e.g., perhaps 1 simultaneous Infinite Thinking agent or a limited number of cycles, and a few Ultra Search queries per day. Despite limits, the free version is fully functional as a single-user productivity tool and intended to provide real value. |
| 10.2 | Pro Subscription (≈ $30 / month): Unlimited advanced models, 20× more autonomy, priority performance. |  | Not Started | Vectal Pro is a paid plan aimed at power users who want the full capabilities without friction. Priced at roughly $30 USD per month (monthly, with an annual option likely at slight discount), this plan includes: Unlimited access to advanced models (Pro users can leverage GPT-4.5, Claude 3.7 Sonnet, and other top models as much as needed), increased agent allowances (Pro offers "20× more Infinite Thinking" usage and "10× more Ultra Search" queries compared to free), priority performance (paying users likely get priority in processing queues), additional features (all new features are generally included in Pro by default), and support (Pro subscribers may receive dedicated support and possibly access to an exclusive community). |
| 10.3 | Enterprise / Team Plans: Custom pricing, SSO, data‑isolation options. |  | Not Started | While not heavily advertised yet, Vectal's site and listings hint at custom enterprise pricing for larger organizations. This suggests volume discounts or multiple seats for teams who want to onboard several users with a managed admin panel, and additional security features like single sign-on (SSO), data isolation, on-premise deployment options for companies with strict compliance needs. The pricing for enterprise is not published; it would be negotiated case-by-case ("Contact sales" approach) once Vectal has the bandwidth to support such clients. |
| 10.4 | Cost Justification: Aggregates expensive models into affordable bundle. |  | Not Started | The $30/month Pro fee is set to be significantly lower than the raw cost of individually subscribing to similar AI services (for instance, OpenAI's ChatGPT-4 plus another Claude subscription, etc.). David Ondrej (Vectal's founder) has highlighted that part of Vectal's value is offering expensive AI cheaply by optimizing usage across users. Essentially, Vectal acts as a middle layer purchasing large blocks of API capacity and distributing it. This pricing strategy is meant to drive adoption by power users who otherwise might not afford direct access to these models. |
| 10.5 | Revenue & Scale: ~$100 k ARR as of mid‑2025, growing via content & community. |  | Not Started | As of mid-2025, Vectal is a startup that reached ~$100,000 in revenue (as indicated by the founder in content) and is growing its user base via content marketing (YouTube) and community. The freemium model supports viral growth (free users spread the word) while conversion to Pro monetizes the heavy users. The sustainability depends on keeping AI API costs below the subscription revenues – which is managed by usage limits and the assumption that not all users use their maximum allotment every month. |
| 10.6 | Comparative Positioning: Competitive vs. single‑model services. |  | Not Started | The pricing is competitive with similar AI productivity tools. For context, a typical user paying $20–$50 for a single-model AI service might find $30 for a multi-agent, multi-model platform very reasonable. Vectal's continuous improvements (v57 and counting) are part of the value proposition to encourage users that the subscription keeps getting better. This positioning helps justify the cost by demonstrating superior value compared to using multiple separate AI services. |
| 10.7 | Upgrades & Downgrades: One‑click, with data retention for downgraded accounts. |  | Not Started | The product likely allows easy upgrading (one-click upgrade in the app) and downgrading. Data is retained if a Pro user downgrades to free, but any Pro-specific features would become read-only or inactive (e.g., their AI Chips might stay stored but not function until they resubscribe). This ensures users don't feel locked in and can come back to Pro when they need heavy usage, reducing the barrier to trying the Pro subscription. |